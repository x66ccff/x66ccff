<div align="center">
  <!-- 1. ‰øùÁïô‰Ω†ÁöÑ GIF -->
  <img src="vsinger-vocaloid.gif" alt="V Singer Animation" width="30%">

  <!-- 2. ‰ΩøÁî®Âä®ÊÄÅ SVG ÂÆûÁé∞ÂéüÊú¨ CSS ‰∏≠ÁöÑ„ÄêÈùíËâ≤Â≠ó‰Ωì„ÄëÂíå„ÄêÊâìÂ≠óÊú∫Â≠ó‰Ωì„ÄëÊïàÊûú -->
  <!-- Â≠ó‰ΩìÈ¢úËâ≤‰ΩøÁî®‰∫Ü‰Ω† CSS ‰∏≠ÁöÑ #66FFFF (Cyan) Âíå #3B82F6 (Blue) -->
  <br/>
  <a href="https://github.com/x66ccff">
    <img src="https://readme-typing-svg.herokuapp.com?font=Space+Mono&weight=700&size=30&duration=3000&pause=1000&color=3B82F6&center=true&vCenter=true&width=500&lines=Hi+there,+I'm+Kai+Ruan;Ph.D.+Student+@+RUC+GSAI" alt="Typing SVG" />
  </a>

  <!-- 3. Á§æ‰∫§ÈìæÊé•Ôºö‰øùÊåÅËìùËâ≤Á≥ªÈ£éÊ†º -->
  <p>
    <a href="https://scholar.google.com/citations?user=tokSmGMAAAAJ">
      <img src="https://img.shields.io/badge/Google_Scholar-4285F4?style=flat-square&logo=google-scholar&logoColor=white" alt="Google Scholar">
    </a>
    <a href="https://github.com/x66ccff">
      <img src="https://img.shields.io/badge/GitHub-181717?style=flat-square&logo=github&logoColor=white" alt="GitHub">
    </a>
    <a href="https://huggingface.co/6cf">
      <img src="https://img.shields.io/badge/Hugging_Face-FFD21E?style=flat-square&logo=huggingface&logoColor=black" alt="Hugging Face">
    </a>
    <a href="mailto:kairuan@ruc.edu.cn">
      <img src="https://img.shields.io/badge/Email-0078D4?style=flat-square&logo=microsoft-outlook&logoColor=white" alt="Email">
    </a>
  </p>
</div>

---

### üí† Experience

<!-- ‰ΩøÁî®ËìùËâ≤ Emoji Â¢ûÂº∫ËßÜËßâ‰∏ªÈ¢ò -->
*   **2026** üîπ Research Intern @ **ByteDance** <br> _Multimodal LLM Reinforcement Learning_
*   **2025** üîπ Research Intern @ **OpenBMB** <br> _Multimodal LLM Reinforcement Learning_

### üéì Education

*   **2023 - Present** üî∑ **Ph.D. Student** <br> Gaoling School of Artificial Intelligence, **Renmin University of China (RUC)**
*   **2019 - 2023** üî∑ **B.E. Computer Science** <br> School of Artificial Intelligence, **Xidian University**

---

### üìù Selected Publications

<!-- ËÆ∫ÊñáÂàóË°®Ôºö‰ΩøÁî®‰∫Ü‰Ω†Ë¶ÅÊ±ÇÁöÑ Nature ÂæΩÁ´†È£éÊ†ºÔºåÂπ∂‰∏∫ CVPR/AAAI ÈÖçËâ≤‰∏∫ËìùËâ≤ -->

<table>
  <!-- Paper 1: Nature Comp Sci -->
  <tr>
    <td width="25%"><img src="https://x66ccff.github.io/images/thumbnails/paper-nature-cs.png" alt="Nature CS" style="border-radius: 8px;"></td>
    <td>
      <strong>Discovering physical laws with parallel symbolic enumeration</strong>
      <br><br>
      <a href="https://www.nature.com/articles/s43588-025-00904-8">
        <img src="https://img.shields.io/badge/Article-Nature_Computational_Science-E30613.svg?style=flat-square&logo=nature" alt="Nature CS">
      </a>
      <img src="https://img.shields.io/badge/Cover_Article-Vol_6_Issue_1-FFD700?style=flat-square" alt="Cover">
      <br>
      <em><strong>Kai Ruan</strong>, Yilong Xu, Ze-Feng Gao, Yang Liu, Yike Guo, Ji-Rong Wen, Hao Sun</em>
      <br><br>
      <a href="https://doi.org/10.1038/s43588-025-00904-8"><img src="https://img.shields.io/badge/DOI-10.1038-blue?style=flat-square&logo=doi&logoColor=white"></a>
      <a href="https://www.nature.com/articles/s43588-025-00904-8.pdf"><img src="https://img.shields.io/badge/PDF-Download-b31b1b?style=flat-square&logo=adobe-acrobat&logoColor=white"></a>
      <a href="https://github.com/intell-sci-comput/PSE"><img src="https://img.shields.io/badge/Code-GitHub-181717?style=flat-square&logo=github"></a>
    </td>
  </tr>

  <!-- Paper 2: Nature Comms -->
  <tr>
    <td width="25%"><img src="https://x66ccff.github.io/images/thumbnails/paper-liveidea.png" alt="LiveIdeaBench" style="border-radius: 8px;"></td>
    <td>
      <strong>Evaluating LLMs' Scientific Creativity and Idea Generation with Minimal Context</strong>
      <br><br>
      <a href="https://www.nature.com/ncomms/">
        <img src="https://img.shields.io/badge/Article-Nature_Communications-E30613.svg?style=flat-square&logo=nature" alt="Nature Comms">
      </a>
      <img src="https://img.shields.io/badge/Status-In_Press-0066CC?style=flat-square" alt="In Press">
      <br>
      <em><strong>Kai Ruan</strong>, Xuan Wang, Jixiang Hong, Hao Sun</em>
      <br><br>
      <a href="https://arxiv.org/abs/2412.17596"><img src="https://img.shields.io/badge/arXiv-2412.17596-B31B1B?style=flat-square&logo=arxiv&logoColor=white"></a>
      <a href="https://github.com/x66ccff/liveideabench"><img src="https://img.shields.io/badge/Code-GitHub-181717?style=flat-square&logo=github"></a>
      <a href="https://huggingface.co/datasets/6cf/liveideabench-v2"><img src="https://img.shields.io/badge/Dataset-HuggingFace-FFD21E?style=flat-square&logo=huggingface&logoColor=black"></a>
    </td>
  </tr>

  <!-- Paper 3: Swarm -->
  <tr>
    <td width="25%"><img src="https://x66ccff.github.io/images/thumbnails/paper-swarm.png" alt="Swarm" style="border-radius: 8px;"></td>
    <td>
      <strong>Benchmarking LLMs' Swarm Intelligence</strong>
      <br><br>
      <img src="https://img.shields.io/badge/Preprint-arXiv-B31B1B?style=flat-square&logo=arxiv&logoColor=white" alt="ArXiv">
      <br>
      <em><strong>Kai Ruan</strong>, Mowen Huang, Ji-Rong Wen, Hao Sun</em>
      <br><br>
      <a href="https://arxiv.org/abs/2505.04364"><img src="https://img.shields.io/badge/PDF-Read-B31B1B?style=flat-square&logo=adobe-acrobat&logoColor=white"></a>
      <a href="https://github.com/RUC-GSAI/YuLan-SwarmIntell"><img src="https://img.shields.io/badge/Code-GitHub-181717?style=flat-square&logo=github"></a>
    </td>
  </tr>

  <!-- Paper 4: CVPR -->
  <tr>
    <td width="25%"><img src="https://x66ccff.github.io/images/thumbnails/paper-animo.png" alt="AniMo" style="border-radius: 8px;"></td>
    <td>
      <strong>AniMo: Species-Aware Model for Text-Driven Animal Motion Generation</strong>
      <br><br>
      <!-- CVPR ËìùËâ≤ÂæΩÁ´† -->
      <img src="https://img.shields.io/badge/Conference-CVPR_2025-1C5299?style=flat-square&logo=computer-vision&logoColor=white" alt="CVPR 2025">
      <br>
      <em>Xuan Wang*, <strong>Kai Ruan*</strong>, X Zhang, G Wang</em>
      <br><br>
      <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_AniMo_Species-Aware_Model_for_Text-Driven_Animal_Motion_Generation_CVPR_2025_paper.pdf"><img src="https://img.shields.io/badge/PDF-OpenAccess-1C5299?style=flat-square&logo=adobe-acrobat&logoColor=white"></a>
      <a href="https://github.com/WandererXX/AniMo"><img src="https://img.shields.io/badge/Code-GitHub-181717?style=flat-square&logo=github"></a>
    </td>
  </tr>

  <!-- Paper 5: AAAI -->
  <tr>
    <td width="25%"><img src="https://x66ccff.github.io/images/thumbnails/paper-xmogen.png" alt="X-MoGen" style="border-radius: 8px;"></td>
    <td>
      <strong>X-MoGen: Unified Motion Generation across Humans and Animals</strong>
      <br><br>
      <!-- AAAI ËìùËâ≤ÂæΩÁ´† -->
      <img src="https://img.shields.io/badge/Conference-AAAI_2025-005596?style=flat-square&logo=doi&logoColor=white" alt="AAAI 2025">
      <br>
      <em>Xuan Wang*, <strong>Kai Ruan*</strong>, L Qian, Z Guo, C Su, G Wang</em>
      <br><br>
      <a href="https://arxiv.org/pdf/2508.05162"><img src="https://img.shields.io/badge/PDF-ArXiv-B31B1B?style=flat-square&logo=adobe-acrobat&logoColor=white"></a>
      <a href="https://github.com/WandererXX/X-MoGen"><img src="https://img.shields.io/badge/Code-GitHub-181717?style=flat-square&logo=github"></a>
    </td>
  </tr>
</table>

<br>

<div align="center">
  <img src="https://komarev.com/ghpvc/?username=x66ccff&style=flat-square&color=blue" alt="Visitor Count" />
</div>
